{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import critic\n",
    "import random\n",
    "from string import ascii_letters\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import ojsim\n",
    "sim = ojsim.OJSimulator()\n",
    "X,y = sim.formulized_train\n",
    "X.shape, y.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# fourier on log price\n",
    "X_pr = X[-8000:,0,:,:]\n",
    "\n",
    "from joblib import delayed,Parallel, parallel_backend\n",
    "def inner(i,j):\n",
    "    window = 20\n",
    "    filtered = np.zeros(40,dtype=complex)\n",
    "    raw_fft = np.fft.fft(X_pr[i,:,j])\n",
    "    filtered[:window] = raw_fft[:window]\n",
    "    filtered[-window:] = raw_fft[-window:]\n",
    "    return np.fft.ifft(filtered)\n",
    "\n",
    "def outer(i):\n",
    "    return np.array(Parallel(n_jobs=-1)(delayed(inner)(i,j) for j in range(10)),dtype = complex)\n",
    "\n",
    "result = np.array(Parallel(n_jobs=-1)(delayed(outer)(i) for i in range(8000)),dtype = complex)\n",
    "input = np.concatenate((result.real, result.imag), axis = 2)\n",
    "input.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "output = y[-8000:,:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def FastAllFeatureExtract(A):\n",
    "    d = 28\n",
    "    A0_pr = A[:, :1440]\n",
    "    A0_vo = A[:, 1440:] + 1\n",
    "    feature = A0_pr[:, -1] - A0_pr[:, 0]\n",
    "    # VO volumn log################\n",
    "    feature = np.concatenate((feature[:, None], np.log(A0_vo[:, -30+d:])), axis=1)\n",
    "\n",
    "    # VO moving avg (#sample,91:120)########\n",
    "    avg_step = 30\n",
    "    df_vo = pd.DataFrame(A0_vo[:, -59+d:].T)\n",
    "    ma_30 = lambda x: x.rolling(avg_step).mean()\n",
    "    df_vo.apply(ma_30).apply(np.log).T.to_numpy()[:, avg_step - 1:]\n",
    "    feature = np.append(feature, df_vo.apply(ma_30).apply(np.log).T.to_numpy()[:, -30+d:], axis=1)\n",
    "\n",
    "    # PR rate of change (#sample, 271:300)#######\n",
    "    df_pr = pd.DataFrame(A0_pr[:, -31:].T)\n",
    "    pct_chg_fxn = lambda x: x.pct_change()\n",
    "    # print(\"PR rate of change\", df_pr.apply(pct_chg_fxn).T.to_numpy()[:,-30:])\n",
    "    feature = np.append(feature, df_pr.apply(pct_chg_fxn).T.to_numpy()[:, -30+d:], axis=1)\n",
    "\n",
    "    # PR moving avg (#sample,301:330)  #######\n",
    "    df_pr = pd.DataFrame(A0_pr[:, -59:].T)\n",
    "    avg_step = 30\n",
    "    ma_30 = lambda x: x.rolling(avg_step).mean()\n",
    "    df_pr.apply(ma_30).T.to_numpy()[:, avg_step - 1:]\n",
    "    # print(\"PR moving avg\", df_pr.apply(ma_30).T.to_numpy()[:,-30:])\n",
    "    feature = np.append(feature, df_pr.apply(ma_30).T.to_numpy()[:, -30+d:], axis=1)\n",
    "\n",
    "    # PR binning (#sample, 331:360)#########\n",
    "    df_pr = pd.DataFrame(A0_pr[:, -30+d:].T)\n",
    "    n_bins = 10\n",
    "    bin_fxn = lambda y: pd.qcut(y, q=n_bins, labels=range(1, n_bins + 1))\n",
    "    binning = df_pr.apply(bin_fxn).T\n",
    "    # print(\"PR binning\", binning.to_numpy()[:,-30:])\n",
    "    feature = np.append(feature, binning.to_numpy(), axis=1)\n",
    "\n",
    "    return feature"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "(8000, 10, 11)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract features\n",
    "X_vo = X[-8000:,1,:,:]\n",
    "X_total = np.concatenate((X_pr,X_vo),axis = 1)\n",
    "def Feature(i):\n",
    "    return FastAllFeatureExtract(X_total[:,:,i])\n",
    "feature_extract = np.array(Parallel(n_jobs=-1)(delayed(Feature)(i) for i in range(10)))\n",
    "feature_extract = feature_extract.swapaxes(0,1)\n",
    "feature_extract.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "((8000, 10, 91), (8000, 10))"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the input\n",
    "IInput =np.concatenate((input,feature_extract),axis=2)\n",
    "IInput.shape, output.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train the pairwise correlation\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from joblib import Parallel, delayed\n",
    "from pickle import dump\n",
    "def train(i):\n",
    "    reg = GradientBoostingRegressor().fit(IInput[:,i,:],output[:,i])\n",
    "    dump(reg, open(f'{i}.FFXGB','wb'))\n",
    "linear_models = Parallel(n_jobs=-1)(delayed(train)(i) for i in range(10))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "linear_models = []\n",
    "for i in range(10):\n",
    "    linear_models.append(load(open(f'{i}.FFXGB','rb')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "OOutput = np.empty((8000,10),dtype=float)\n",
    "for i in range(8000):\n",
    "    OOutput[i,:] = np.array([linear_models[j].predict(IInput[i,[j],:]) for j in range(10)]).reshape(-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def get_batch(X, Y, batch_size=16):\n",
    "    X, Y = X.float(), Y.float()\n",
    "    n = X.size()[0]\n",
    "    indices = torch.randint(low=0, high=n, size=(batch_size,))\n",
    "    return X[indices], Y[indices]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "IIIInput = OOutput - X_pr[:,-1,:]\n",
    "YYput = output - X_pr[:,-1,:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [2]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mRescale\u001B[39;00m(\u001B[43mnn\u001B[49m\u001B[38;5;241m.\u001B[39mModule):\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m      3\u001B[0m         \u001B[38;5;28msuper\u001B[39m(Rescale, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class Rescale(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Rescale, self).__init__()\n",
    "        # fc = []\n",
    "        # for i in range(10):\n",
    "        #     fc.append(nn.Linear(1, 1, bias = True))\n",
    "        # self.fc = nn.ModuleList(fc)\n",
    "        # self.zzw = 10*torch.rand((10,1))#10*torch.FloatTensor(np.ones((10,1)))\n",
    "        # self.zzw.requires_grad_()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print((x[:,0])[:,None].shape)\n",
    "        out = torch.empty((x.shape),dtype=torch.float)\n",
    "        for i in range(x.shape[0]):\n",
    "            for j in range(10):\n",
    "            #print(x[i,:].shape)\n",
    "                out[i,j] = x[i,j] * self.zzw[j] *self.zzw[j]\n",
    "                #out[i,j] = x[i,j] * self.zzw[j] *self.zzw[j]\n",
    "        return out\n",
    "        #return torch.FloatTensor([self.fc[i]((x[:,i])[:,None]) for i in range(10)])\n",
    "\n",
    "\n",
    "\n",
    "final_model = Rescale()               # Moving the model to GPU if available\n",
    "criterion = nn.MSELoss()                         # One possible loss criterion\n",
    "learning_rate = 1\n",
    "optimizer = torch.optim.Adam([final_model.zzw],lr=learning_rate)#torch.optim.SGD(final_model.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "training_steps = 1000\n",
    "for i in range(training_steps):\n",
    "    minibatch_x, minibatch_y = get_batch(torch.FloatTensor(IIIInput), torch.FloatTensor(YYput))\n",
    "    output = final_model(minibatch_x)\n",
    "    stacked = torch.stack([output, minibatch_y]) #2 x b x 10\n",
    "    stacked = stacked.transpose(1,2).transpose(0,1) # 10 x 2 x b\n",
    "    corrs = torch.stack([torch.corrcoef(stacked[i])[0,1] for i in range(10)]) # 10 x 1\n",
    "    loss = -torch.mean(corrs)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(i,loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [3]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mfinal_model\u001B[49m\u001B[38;5;241m.\u001B[39mzzw\n",
      "\u001B[1;31mNameError\u001B[0m: name 'final_model' is not defined"
     ]
    }
   ],
   "source": [
    "final_model.zzw"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(final_model.state_dict(), \"final_scale.mdl\")\n",
    "# load model\n",
    "# final_model = Rescale()\n",
    "# final_model.load_state_dict(torch.load(\"final_scale.mdl\"))\n",
    "# final_model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8496 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'linear_models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [6]\u001B[0m, in \u001B[0;36m<cell line: 21>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mojsim\u001B[39;00m\n\u001B[0;32m     20\u001B[0m sim \u001B[38;5;241m=\u001B[39m ojsim\u001B[38;5;241m.\u001B[39mOJSimulator()\n\u001B[1;32m---> 21\u001B[0m \u001B[43msim\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msubmit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mget_r_hat\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m\\\\engin-labs.m.storage.umich.edu\\tywwyt\\windat.V2\\Documents\\GitHub\\stats601-project\\ojsim.py:14\u001B[0m, in \u001B[0;36mOJSimulator.submit\u001B[1;34m(self, get_r_hat)\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msubmit\u001B[39m(\u001B[38;5;28mself\u001B[39m, get_r_hat):\n\u001B[0;32m     13\u001B[0m     log_pr, volu \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset_\u001B[38;5;241m.\u001B[39mtest_set\n\u001B[1;32m---> 14\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcritic_\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msubmit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mget_r_hat\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlog_pr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvolu\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m\\\\engin-labs.m.storage.umich.edu\\tywwyt\\windat.V2\\Documents\\GitHub\\stats601-project\\critic.py:68\u001B[0m, in \u001B[0;36mCritic.submit\u001B[1;34m(self, get_r_hat, log_pr, volu)\u001B[0m\n\u001B[0;32m     67\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msubmit\u001B[39m(\u001B[38;5;28mself\u001B[39m, get_r_hat, log_pr, volu):\n\u001B[1;32m---> 68\u001B[0m     t_used, pairwise, overall \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscore\u001B[49m\u001B[43m(\u001B[49m\u001B[43mget_r_hat\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlog_pr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvolu\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTotal time used: \u001B[39m\u001B[38;5;132;01m%.3f\u001B[39;00m\u001B[38;5;124ms\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m t_used)\n\u001B[0;32m     70\u001B[0m     pairwise_report \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPairwise correlation:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[1;32m\\\\engin-labs.m.storage.umich.edu\\tywwyt\\windat.V2\\Documents\\GitHub\\stats601-project\\critic.py:47\u001B[0m, in \u001B[0;36mCritic.score\u001B[1;34m(self, get_r_hat, log_pr, volu)\u001B[0m\n\u001B[0;32m     43\u001B[0m r_hat \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(index\u001B[38;5;241m=\u001B[39mlog_pr\u001B[38;5;241m.\u001B[39mindex[\u001B[38;5;241m1440\u001B[39m::\u001B[38;5;241m10\u001B[39m],\n\u001B[0;32m     44\u001B[0m                      columns\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39marange(\u001B[38;5;241m10\u001B[39m),\n\u001B[0;32m     45\u001B[0m                      dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mfloat64)\n\u001B[0;32m     46\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m tqdm(log_pr\u001B[38;5;241m.\u001B[39mindex[\u001B[38;5;241m1440\u001B[39m::\u001B[38;5;241m10\u001B[39m]):  \u001B[38;5;66;03m# compute the predictions every day\u001B[39;00m\n\u001B[1;32m---> 47\u001B[0m     r_hat\u001B[38;5;241m.\u001B[39mloc[t, :] \u001B[38;5;241m=\u001B[39m \u001B[43mget_r_hat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlog_pr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloc\u001B[49m\u001B[43m[\u001B[49m\u001B[43m(\u001B[49m\u001B[43mt\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdt\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\u001B[43mt\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvolu\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloc\u001B[49m\u001B[43m[\u001B[49m\u001B[43m(\u001B[49m\u001B[43mt\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdt\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\u001B[43mt\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     49\u001B[0m t_used \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m t0\n\u001B[0;32m     51\u001B[0m \u001B[38;5;66;03m# Compute true forward log_returns every 10 minutes\u001B[39;00m\n",
      "Input \u001B[1;32mIn [6]\u001B[0m, in \u001B[0;36mget_r_hat\u001B[1;34m(A, B)\u001B[0m\n\u001B[0;32m     13\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m linear_models[i]\u001B[38;5;241m.\u001B[39mpredict(hi)[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m-\u001B[39m A[i,\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m#before_scale =  torch.FloatTensor([getNpredict(i) for i in range(10)] - A[:,-1])\u001B[39;00m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m#after_scale =  final_model(before_scale[None,:])\u001B[39;00m\n\u001B[1;32m---> 16\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39marray([getNpredict(i) \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m10\u001B[39m)]) \u001B[38;5;241m*\u001B[39m np\u001B[38;5;241m.\u001B[39marray([\u001B[38;5;241m3\u001B[39m,\u001B[38;5;241m8\u001B[39m,\u001B[38;5;241m4\u001B[39m,\u001B[38;5;241m8\u001B[39m,\u001B[38;5;241m4\u001B[39m,\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m8\u001B[39m,\u001B[38;5;241m4\u001B[39m,\u001B[38;5;241m10\u001B[39m,\u001B[38;5;241m9\u001B[39m])\n",
      "Input \u001B[1;32mIn [6]\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     13\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m linear_models[i]\u001B[38;5;241m.\u001B[39mpredict(hi)[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m-\u001B[39m A[i,\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m#before_scale =  torch.FloatTensor([getNpredict(i) for i in range(10)] - A[:,-1])\u001B[39;00m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m#after_scale =  final_model(before_scale[None,:])\u001B[39;00m\n\u001B[1;32m---> 16\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39marray([\u001B[43mgetNpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mi\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m10\u001B[39m)]) \u001B[38;5;241m*\u001B[39m np\u001B[38;5;241m.\u001B[39marray([\u001B[38;5;241m3\u001B[39m,\u001B[38;5;241m8\u001B[39m,\u001B[38;5;241m4\u001B[39m,\u001B[38;5;241m8\u001B[39m,\u001B[38;5;241m4\u001B[39m,\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m8\u001B[39m,\u001B[38;5;241m4\u001B[39m,\u001B[38;5;241m10\u001B[39m,\u001B[38;5;241m9\u001B[39m])\n",
      "Input \u001B[1;32mIn [6]\u001B[0m, in \u001B[0;36mget_r_hat.<locals>.getNpredict\u001B[1;34m(i)\u001B[0m\n\u001B[0;32m     11\u001B[0m hi \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mappend(filtered\u001B[38;5;241m.\u001B[39mreal,filtered\u001B[38;5;241m.\u001B[39mimag)[\u001B[38;5;28;01mNone\u001B[39;00m,:]\n\u001B[0;32m     12\u001B[0m hi \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mconcatenate((hi,features[[i],:]),axis \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m---> 13\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlinear_models\u001B[49m[i]\u001B[38;5;241m.\u001B[39mpredict(hi)[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m-\u001B[39m A[i,\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n",
      "\u001B[1;31mNameError\u001B[0m: name 'linear_models' is not defined"
     ]
    }
   ],
   "source": [
    "def get_r_hat(A,B):\n",
    "    A = A.values.T\n",
    "    B = B.values.T\n",
    "    features = FastAllFeatureExtract(np.concatenate((A,B), axis = 1))\n",
    "    window = 20\n",
    "    def getNpredict(i):\n",
    "        filtered = np.zeros(40,dtype=complex)\n",
    "        raw_fft = np.fft.fft(A[i,:])\n",
    "        filtered[:window] = raw_fft[:window]\n",
    "        filtered[-window:] = raw_fft[-window:]\n",
    "        hi = np.append(filtered.real,filtered.imag)[None,:]\n",
    "        hi = np.concatenate((hi,features[[i],:]),axis = 1)\n",
    "        return linear_models[i].predict(hi)[0]- A[i,-1]\n",
    "    #before_scale =  torch.FloatTensor([getNpredict(i) for i in range(10)] - A[:,-1])\n",
    "    #after_scale =  final_model(before_scale[None,:])\n",
    "    return np.array([getNpredict(i) for i in range(10)]) * np.array([3,8,4,8,4,1,8,4,10,9])#\n",
    "    #return after_scale.detach().numpy()\n",
    "\n",
    "import ojsim\n",
    "sim = ojsim.OJSimulator()\n",
    "sim.submit(get_r_hat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# without NN\n",
    "Total time used: 210.160s\n",
    "Pairwise correlation:\n",
    "\tasset 0 = 0.01060\n",
    "\tasset 1 = 0.04222\n",
    "\tasset 2 = 0.04612\n",
    "\tasset 3 = 0.02012\n",
    "\tasset 4 = 0.04990\n",
    "\tasset 5 = 0.02483\n",
    "\tasset 6 = 0.03063\n",
    "\tasset 7 = 0.02822\n",
    "\tasset 8 = 0.02789\n",
    "\tasset 9 = 0.04412\n",
    "\tmean correlation = 0.03247\n",
    "Overall correlation: -0.00005\n",
    "===============================\n",
    "Fail to outperform Ziwei's method, whose pairwise average\n",
    "and overall correlations are (0.02840, 0.01536)\n",
    "==============================="
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NN with bias\n",
    "Total time used: 214.427s\n",
    "Pairwise correlation:\n",
    "\tasset 0 = 0.00510\n",
    "\tasset 1 = 0.04444\n",
    "\tasset 2 = 0.04673\n",
    "\tasset 3 = 0.02996\n",
    "\tasset 4 = -0.05310\n",
    "\tasset 5 = -0.02349\n",
    "\tasset 6 = 0.03267\n",
    "\tasset 7 = -0.02625\n",
    "\tasset 8 = 0.04223\n",
    "\tasset 9 = -0.03679\n",
    "\tmean correlation = 0.00615\n",
    "Overall correlation: -0.01309\n",
    "===============================\n",
    "Fail to outperform Ziwei's method, whose pairwise average\n",
    "and overall correlations are (0.02840, 0.01536)\n",
    "==============================="
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\VApps\\Anaconda3\\envs\\stats601\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      " 20%|██        | 1736/8496 [00:47<03:06, 36.16it/s]"
     ]
    }
   ],
   "source": [
    "import ojsim\n",
    "import main\n",
    "sim = ojsim.OJSimulator()\n",
    "sim.submit(main.get_r_hat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}